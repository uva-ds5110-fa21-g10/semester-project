{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking at the duo features and their effectiveness. Meaning that two or three featueres are used as predictores for the model. We are using Gradient Boosted Trees as the model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fractions import Fraction as frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"fa21-ds5110-group10-rk\") \\\n",
    "    .config(\"spark.driver.memory\", \"36g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://udc-ba33-31c0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>fa21-ds5110-group10-rk</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=fa21-ds5110-group10-rk>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.cancelAllJobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we add in our cached dataset from our prior feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../../data/processed/chess_games_moves_model.parquet\")\n",
    "trainData = spark.read.parquet(\"../../../data/processed/training.parquet\")\n",
    "testData = spark.read.parquet(\"../../../data/processed/testing.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[event: string, white_result: string, first_two: array<string>, ECO: string, EloDiff: int, Opening: string, game_complexity: int, opening_class: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()\n",
    "trainData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+----------------+---+-------+--------------------+---------------+--------------+\n",
      "|event|white_result|       first_two|ECO|EloDiff|             Opening|game_complexity| opening_class|\n",
      "+-----+------------+----------------+---+-------+--------------------+---------------+--------------+\n",
      "|Blitz|         win|[c4 c5, Nc3 Nf6]|A34|    222|English Opening: ...|              6|Flank openings|\n",
      "|Blitz|         win| [d4 b6, c4 Bb7]|A40|    309|  English Defense #2|              5|Flank openings|\n",
      "+-----+------------+----------------+---+-------+--------------------+---------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we review the resulting data points of interest.\n",
    "We notice that ECO and the first two sets of moves are distinct of one another, and may influence the overall model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Turns: 464628\n",
      "ECO Types: 493\n",
      "+------------------+------+\n",
      "|         first_two| count|\n",
      "+------------------+------+\n",
      "|  [e4 e5, Nf3 Nc6]|332412|\n",
      "|   [e4 e5, Nf3 d6]|129785|\n",
      "|[e4 d5, exd5 Qxd5]| 86575|\n",
      "|  [e4 c5, Nf3 Nc6]| 78638|\n",
      "|    [e4 e6, d4 d5]| 72122|\n",
      "+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None 3849646\n"
     ]
    }
   ],
   "source": [
    "print(\"First Turns: {}\".format(df.select(\"first_two\").distinct().count()))\n",
    "print(\"ECO Types: {}\".format(df.select(\"ECO\").distinct().count()))\n",
    "print( df.groupBy('first_two').count().sort(F.col(\"count\").desc()).show(5), df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now begin to build a model, keying in on the opening move and the white_result columns.\n",
    "Note that both of these are categorical values, so we will need to encode them using the StringIndexer for pyspark to do model evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "opening_vectorizor = StringIndexer(inputCol=\"ECO\", outputCol=\"opening_ohe\")\n",
    "gametype_vectorizer = StringIndexer(inputCol=\"event\", outputCol=\"event_vector\")\n",
    "class_vectorizer = StringIndexer(inputCol=\"opening_class\", outputCol=\"opening_class_vector\")\n",
    "# target\n",
    "result_vectorizor = StringIndexer(inputCol=\"white_result\", outputCol=\"white_result_vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform One-Hot Encoding on our Opening type (or ECO) and do our comparision.  THis will create a new column that we will use for our random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_encoder = OneHotEncoder(inputCols=[\"opening_ohe\"],\n",
    "                        outputCols=[\"ECO_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_encoder = OneHotEncoder(inputCols=[\"opening_class_vector\"],\n",
    "                        outputCols=[\"Class_Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the OHE of our ECO, we can combine it with other features to build out our predictors for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_assembler = VectorAssembler(inputCols=['ECO_Type', \"event_vector\",\"EloDiff\"], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is model-ready, we will do a split, fit, transform, and evaluation to determine the performance of our model.\n",
    "Note that we have chosen the default tunings, but in the future we will likely apply a cross-validation technique in pyspark to select the correct hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(maxDepth=5, maxIter=5, labelCol='white_result_vector', seed=1337, leafCol=\"leafId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                            gametype_vectorizer,\n",
    "                            result_vectorizor,\n",
    "                            move_encoder,\n",
    "                            features_assembler])\n",
    "ml_pipeline = Pipeline(stages=[gbt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_model = data_pipeline.fit(df)\n",
    "data_model_train = data_model.transform(trainData)\n",
    "data_model_test = data_model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ml_model = ml_pipeline.fit(data_model_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gbt = GBTClassifier(maxDepth=5, maxIter=10, labelCol='white_result_vector', seed=0, leafCol=\"leafId\")\n",
    "    \n",
    "    \n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "features_assembler = VectorAssembler(inputCols=[\"EloDiff\"], outputCol='features')         \n",
    "data_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                            gametype_vectorizer,\n",
    "                            result_vectorizor,\n",
    "                            move_encoder,\n",
    "                            features_assembler])\n",
    "ml_pipeline = Pipeline(stages=[gbt])\n",
    "        \n",
    "data_model = data_pipeline.fit(df)\n",
    "\n",
    "data_transformed = data_model.transform(df)\n",
    "        \n",
    "trainval = CrossValidator(estimator=ml_pipeline,\n",
    "                                        estimatorParamMaps=paramGrid,\n",
    "                                        evaluator=BinaryClassificationEvaluator(labelCol='white_result_vector'),\n",
    "                                        seed=0,\n",
    "                                        numFolds=10)\n",
    "cvModel = trainval.setParallelism(4).fit(data_transformed) #\n",
    "print((var,cvModel.bestModel.stages[-1].summary.accuracy,cvModel.bestModel.stages[-1].summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_selected = ['ECO_Type', \"Class_Type\",\"EloDiff\"]\n",
    "\n",
    "def compute_univariate_aucs(df, target, varNames, folds, max_iterations, seed):\n",
    "    \n",
    "    #encoder = OneHotEncoder(inputCol=target, outputCol=\"target_one\")\n",
    "    \n",
    "    gbt = GBTClassifier(maxDepth=5, maxIter=max_iterations, labelCol=target, seed=seed, leafCol=\"leafId\")\n",
    "    \n",
    "    \n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .build()\n",
    "        #.addGrid(gbt.subsamplingRate, [0.8, 1]) \\\n",
    "        #.addGrid(gbt.minInstancesPerNode, [2, 10,25]) \\\n",
    "        #.addGrid(gbt.maxDepth, [5, 8]) \\\n",
    "        \n",
    "    results = []\n",
    "    \n",
    "    features_assembler = VectorAssembler(inputCols=varNames, outputCol='features')         \n",
    "    data_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                            gametype_vectorizer,\n",
    "                            class_vectorizer,\n",
    "                            result_vectorizor,\n",
    "                            move_encoder,\n",
    "                            class_encoder,\n",
    "                            features_assembler])\n",
    "    ml_pipeline = Pipeline(stages=[gbt])\n",
    "\n",
    "    data_model = data_pipeline.fit(df)\n",
    "    data_transformed = data_model.transform(df)\n",
    "\n",
    "    trainval = CrossValidator(estimator=ml_pipeline,\n",
    "                                    estimatorParamMaps=paramGrid,\n",
    "                                    evaluator=BinaryClassificationEvaluator(labelCol=target),\n",
    "                                    seed=seed,\n",
    "                                    numFolds=folds)\n",
    "    print(varNames)\n",
    "    cvModel = trainval.setParallelism(4).fit(data_transformed)\n",
    "    \n",
    "    return list(zip(cvModel.avgMetrics, cvModel.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ['ECO_Type', \"Class_Type\"] = 0.5374052433698874\n",
    "** 0.5181187981402716\n",
    "* ['ECO_Type',\"EloDiff\"] = 0.6881870978085711\n",
    "** 0.5715876574872436\n",
    "* [\"Class_Type\",\"EloDiff\"] = 0.6879289557569324\n",
    "** 0.5708519912343532\n",
    "* ['ECO_Type', \"Class_Type\",\"EloDiff\"] = 0.6883014209551042 \n",
    "** 0.5718688758770751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ECO_Type', 'Class_Type']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5373878571367646, {})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1 = compute_univariate_aucs(df, 'white_result_vector', ['ECO_Type', \"Class_Type\"], 10, 10, 0)\n",
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ECO_Type', 'EloDiff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.6881748643702057, {})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = compute_univariate_aucs(df, 'white_result_vector', ['ECO_Type',\"EloDiff\"], 10, 10, 0)\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class_Type', 'EloDiff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.687928041959707, {})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3 = compute_univariate_aucs(df, 'white_result_vector', [\"Class_Type\",\"EloDiff\"], 10, 10, 0)\n",
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ECO_Type', 'Class_Type', 'EloDiff']\n"
     ]
    }
   ],
   "source": [
    "results4 = compute_univariate_aucs(df, 'white_result_vector', vars_selected, 10, 10, 0)\n",
    "results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
