{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"fa21-ds5110-group10\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we add in our cached dataset from our prior feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../../data/processed/chess_games_moves_model.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event: string (nullable = true)\n",
      " |-- white_result: string (nullable = true)\n",
      " |-- WhiteElo: integer (nullable = true)\n",
      " |-- BlackElo: integer (nullable = true)\n",
      " |-- first_two: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ECO: string (nullable = true)\n",
      " |-- Opening: string (nullable = true)\n",
      " |-- game_complexity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we review the resulting data points of interest.\n",
    "We notice that ECO and the first two sets of moves are distinct of one another, and may influence the overall model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Turns: 464628\n",
      "ECO Types: 493\n",
      "Opening Variants: 2897\n",
      "+------------------+------+\n",
      "|         first_two| count|\n",
      "+------------------+------+\n",
      "|  [e4 e5, Nf3 Nc6]|332412|\n",
      "|   [e4 e5, Nf3 d6]|129785|\n",
      "|[e4 d5, exd5 Qxd5]| 86575|\n",
      "|  [e4 c5, Nf3 Nc6]| 78638|\n",
      "|    [e4 e6, d4 d5]| 72122|\n",
      "+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None 3849646\n"
     ]
    }
   ],
   "source": [
    "print(\"First Turns: {}\".format(df.select(\"first_two\").distinct().count()))\n",
    "print(\"ECO Types: {}\".format(df.select(\"ECO\").distinct().count()))\n",
    "print(\"Opening Variants: {}\".format(df.select(\"Opening\").distinct().count()))\n",
    "print( df.groupBy('first_two').count().sort(F.col(\"count\").desc()).show(5), df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now begin to build a model, keying in on the opening move and the white_result columns.\n",
    "Note that both of these are categorical values, so we will need to encode them using the StringIndexer for pyspark to do model evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_vectorizor = StringIndexer(inputCol=\"ECO\", outputCol=\"opening_ohe\")\n",
    "opening_dataframe = opening_vectorizor.fit(df).transform(df)\n",
    "\n",
    "gametype_vectorizer = StringIndexer(inputCol=\"event\", outputCol=\"event_vector\")\n",
    "opening_dataframe = gametype_vectorizer.fit(opening_dataframe).transform(opening_dataframe)\n",
    "\n",
    "result_vectorizor = StringIndexer(inputCol=\"white_result\", outputCol=\"white_result_vector\")\n",
    "opening_dataframe = result_vectorizor.fit(opening_dataframe).transform(opening_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+--------+----------------+---+--------------------+---------------+-----------+------------+-------------------+\n",
      "|    event|white_result|WhiteElo|BlackElo|       first_two|ECO|             Opening|game_complexity|opening_ohe|event_vector|white_result_vector|\n",
      "+---------+------------+--------+--------+----------------+---+--------------------+---------------+-----------+------------+-------------------+\n",
      "|    Blitz|         win|    2068|    1846|[c4 c5, Nc3 Nf6]|A34|English Opening: ...|              6|      133.0|         0.0|                0.0|\n",
      "|    Blitz|         win|    1708|    1399| [d4 b6, c4 Bb7]|A40|  English Defense #2|              5|        6.0|         0.0|                0.0|\n",
      "|Classical|        loss|    1542|    1790| [e4 Nc6, d4 d5]|B00|Nimzowitsch Defen...|              7|        7.0|         1.0|                1.0|\n",
      "+---------+------------+--------+--------+----------------+---+--------------------+---------------+-----------+------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opening_dataframe.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform One-Hot Encoding on our Opening type (or ECO) and do our comparision.  THis will create a new column that we will use for our random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+--------+--------------------+---+--------------------+---------------+-----------+------------+-------------------+-----------------+\n",
      "|    event|white_result|WhiteElo|BlackElo|           first_two|ECO|             Opening|game_complexity|opening_ohe|event_vector|white_result_vector|         ECO_Type|\n",
      "+---------+------------+--------+--------+--------------------+---+--------------------+---------------+-----------+------------+-------------------+-----------------+\n",
      "|    Blitz|         win|    2068|    1846|    [c4 c5, Nc3 Nf6]|A34|English Opening: ...|              6|      133.0|         0.0|                0.0|(492,[133],[1.0])|\n",
      "|    Blitz|         win|    1708|    1399|     [d4 b6, c4 Bb7]|A40|  English Defense #2|              5|        6.0|         0.0|                0.0|  (492,[6],[1.0])|\n",
      "|Classical|        loss|    1542|    1790|     [e4 Nc6, d4 d5]|B00|Nimzowitsch Defen...|              7|        7.0|         1.0|                1.0|  (492,[7],[1.0])|\n",
      "|    Blitz|         win|    1467|    1679|    [e4 e5, d4 exd4]|C21|       Danish Gambit|              4|       27.0|         0.0|                0.0| (492,[27],[1.0])|\n",
      "|    Blitz|        loss|    1249|    1174|    [e4 e5, d4 exd4]|C22|Center Game: Paul...|              4|       51.0|         0.0|                1.0| (492,[51],[1.0])|\n",
      "|Classical|        loss|    1559|    1848|      [e4 e6, d4 d5]|C01|French Defense: E...|              5|       32.0|         1.0|                1.0| (492,[32],[1.0])|\n",
      "|    Blitz|        loss|    2041|    2000|      [d4 d5, c4 c6]|D45|Semi-Slav Defense...|              5|      107.0|         0.0|                1.0|(492,[107],[1.0])|\n",
      "|Classical|         win|    1773|    1809|    [e4 e5, Nf3 Nc6]|C62|Ruy Lopez: Steini...|              7|       43.0|         1.0|                0.0| (492,[43],[1.0])|\n",
      "|    Blitz|        loss|    1515|    1409|     [d4 g6, c4 Bg7]|A40|      Modern Defense|              4|        6.0|         0.0|                1.0|  (492,[6],[1.0])|\n",
      "|Classical|         win|    1609|    1594|     [c3 e6, e3 Qf6]|A00|   Saragossa Opening|              5|        0.0|         1.0|                0.0|  (492,[0],[1.0])|\n",
      "|    Blitz|         win|    1959|    1735|      [d4 d5, e3 e6]|D00|Queen's Pawn Game #2|              2|        3.0|         0.0|                0.0|  (492,[3],[1.0])|\n",
      "|    Blitz|         win|    1908|    1836|     [e4 e5, Nf3 d6]|C41| Philidor Defense #2|              6|        4.0|         0.0|                0.0|  (492,[4],[1.0])|\n",
      "|Classical|         win|    1799|    1791|[Nf3 { [%eval 0.1...|A46|Indian Game: Czec...|              5|       53.0|         1.0|                0.0| (492,[53],[1.0])|\n",
      "|Classical|        loss|    1612|    1845|    [e4 e5, Bc4 Bc5]|C20|Bishop's Opening:...|              5|        5.0|         1.0|                1.0|  (492,[5],[1.0])|\n",
      "|Classical|         win|    1385|    1353|    [e4 e5, Nf3 Nc6]|C47|Four Knights Game...|              4|       77.0|         1.0|                0.0| (492,[77],[1.0])|\n",
      "|    Blitz|         win|    1485|    1011|    [d4 f5, Bf4 Nc6]|A80|       Dutch Defense|              3|       68.0|         0.0|                0.0| (492,[68],[1.0])|\n",
      "|    Blitz|        loss|    1398|    1396|    [e4 e5, Nf3 Nc6]|C55|Italian Game: Ant...|              3|       17.0|         0.0|                1.0| (492,[17],[1.0])|\n",
      "|    Blitz|        loss|    1504|    1613|      [e4 c5, f4 e6]|B21|Sicilian Defense:...|              6|       16.0|         0.0|                1.0| (492,[16],[1.0])|\n",
      "|    Blitz|         win|    1881|    1328|    [d4 Nf6, Nc3 d5]|D01|Queen's Pawn Game...|              2|       55.0|         0.0|                0.0| (492,[55],[1.0])|\n",
      "|    Blitz|        loss|    2012|    1990|     [d4 d5, c4 Nc6]|D07|Queen's Gambit Re...|              5|       79.0|         0.0|                1.0| (492,[79],[1.0])|\n",
      "+---------+------------+--------+--------+--------------------+---+--------------------+---------------+-----------+------------+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=[\"opening_ohe\"],\n",
    "                        outputCols=[\"ECO_Type\"])\n",
    "model = encoder.fit(opening_dataframe)\n",
    "encoded = model.transform(opening_dataframe)\n",
    "\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the OHE of our ECO, we can combine it with other features to build out our predictors for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_assembler = VectorAssembler(inputCols=['ECO_Type', \"event_vector\"], outputCol='features')\n",
    "encoded = features_assembler.transform(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is model-ready, we will do a split, fit, transform, and evaluation to determine the performance of our model.\n",
    "Note that we have chosen the default tunings, but in the future we will likely apply a cross-validation technique in pyspark to select the correct hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData, validationData  = encoded.randomSplit([0.6, 0.3, 0.1], seed=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(numTrees=20, maxDepth=5, featuresCol='features', labelCol='white_result_vector', seed=1337, leafCol=\"leafId\")\n",
    "rf_model = rf.fit(trainData)\n",
    "rf_result = rf_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluator = BinaryClassificationEvaluator(labelCol='white_result_vector', metricName='areaUnderROC')\n",
    "model_accuracy = accuracy_evaluator.evaluate(rf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.524294869672513\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy: {}\".format(model_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that our model's performance seems to work well, with roughtly 50% of games resulting in a match to white win.\n",
    "\n",
    "Let's review our classifications and confusion matrix next to determine the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[621708.      0.]\n",
      " [534408.      0.]]\n"
     ]
    }
   ],
   "source": [
    "designer_matrix = rf_result.select(['prediction','white_result_vector'])\n",
    "metrics_rdd = MulticlassMetrics(designer_matrix.rdd.map(tuple))\n",
    "print(metrics_rdd.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing this model, we see that this model is not good.\n",
    "Of the three classes, we found that the precision for the white loss performs okay, however the white win and tie both evaluate to 0 for precision.\n",
    "This means that our model is overfitting and failed to correctly identify either ties or losses.\n",
    "\n",
    "Further tuning will be required to better distribute our data (either adjusting the threshold, or tuning the tree)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
