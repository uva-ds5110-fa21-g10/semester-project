{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experement 3 - Naive Bayes\n",
    "\n",
    "## DS 5110\n",
    "* Fall 2021\n",
    "* Xin Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from fractions import Fraction as frac\n",
    "\n",
    "SEED = 1337\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Spark Sesson and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"fa21-ds5110-group10-xh\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://udc-ba33-31c0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>fa21-ds5110-group10-xh</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=fa21-ds5110-group10-xh>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we add in our cached dataset from our prior feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../../data/processed/training.parquet\")\n",
    "testing_df = spark.read.parquet(\"../../../data/processed/testing.parquet\")\n",
    "\n",
    "df_all = spark.read.parquet(\"../../../data/processed/chess_games_moves_model.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[event: string, white_result: string, first_two: array<string>, ECO: string, EloDiff: int, Opening: string, game_complexity: int, opening_class: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we review the resulting data points of interest.\n",
    "We notice that ECO and the first two sets of moves are distinct of one another, and may influence the overall model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Turns: 289154\n",
      "ECO Types: 491\n",
      "Opening Variants: 2832\n",
      "+------------------+------+\n",
      "|         first_two| count|\n",
      "+------------------+------+\n",
      "|  [e4 e5, Nf3 Nc6]|199152|\n",
      "|   [e4 e5, Nf3 d6]| 77714|\n",
      "|[e4 d5, exd5 Qxd5]| 51726|\n",
      "|  [e4 c5, Nf3 Nc6]| 46965|\n",
      "|    [e4 e6, d4 d5]| 43334|\n",
      "+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None 2308233\n"
     ]
    }
   ],
   "source": [
    "print(\"First Turns: {}\".format(df.select(\"first_two\").distinct().count()))\n",
    "print(\"ECO Types: {}\".format(df.select(\"ECO\").distinct().count()))\n",
    "print(\"Opening Variants: {}\".format(df.select(\"Opening\").distinct().count()))\n",
    "print( df.groupBy('first_two').count().sort(F.col(\"count\").desc()).show(5), df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering (Feature Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now begin to build a model, keying in on the opening move and the white_result columns.\n",
    "Note that both of these are categorical values, so we will need to encode them using the StringIndexer for pyspark to do model evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_vectorizor = StringIndexer(inputCol=\"ECO\", outputCol=\"opening_ohe\")\n",
    "gametype_vectorizer = StringIndexer(inputCol=\"event\", outputCol=\"event_vector\")\n",
    "result_vectorizor = StringIndexer(inputCol=\"white_result\", outputCol=\"white_result_vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform One-Hot Encoding on our Opening type (or ECO) and do our comparision.  THis will create a new column that we will use for our random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_encoder = OneHotEncoder(inputCols=[\"opening_ohe\"],\n",
    "                             outputCols=[\"ECO_Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the OHE of our ECO, we can combine it with other features to build out our predictors for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_assembler = VectorAssembler(inputCols=['ECO_Type', \"EloDiff\", \"event_vector\"], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is model-ready, we will do a split, fit, transform, and evaluation to determine the performance of our model.\n",
    "Note that we have chosen the default tunings, but in the future we will likely apply a cross-validation technique in pyspark to select the correct hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                                    gametype_vectorizer,\n",
    "                                    result_vectorizor,\n",
    "                                    move_encoder,\n",
    "                                   features_assembler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a RandomForest Model based on One Set of Pre-defined Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(numTrees=20, maxDepth=5, featuresCol='features', labelCol='white_result_vector', seed=SEED, leafCol=\"leafId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our transforms from our full dataset (considers all cases)\n",
    "feature_model_df = feature_pipeline.fit(df_all)\n",
    "\n",
    "# Transform both training and testing dfs\n",
    "trainingData = feature_model_df.transform(df)\n",
    "testingData = feature_model_df.transform(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_evaluator = BinaryClassificationEvaluator(labelCol='white_result_vector', metricName='areaUnderROC')\n",
    "model_auc = auc_evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AreaUnderROC: 0.6571804526107925\n"
     ]
    }
   ],
   "source": [
    "print(\"Model AreaUnderROC: {}\".format(model_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that our model's performance seems to work well, with roughtly 50% of games resulting in a match to white win.\n",
    "\n",
    "Let's review our classifications and confusion matrix next to determine the overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[381983. 199779.]\n",
      " [227090. 347270.]]\n"
     ]
    }
   ],
   "source": [
    "designer_matrix = prediction.select(['prediction','white_result_vector'])\n",
    "metrics_rdd = MulticlassMetrics(designer_matrix.rdd.map(tuple))\n",
    "print(metrics_rdd.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing this model, we see that this model is not good.\n",
    "Of the three classes, we found that the precision for the white loss performs okay, however the white win and tie both evaluate to 0 for precision.\n",
    "This means that our model is overfitting and failed to correctly identify either ties or losses.\n",
    "\n",
    "Further tuning will be required to better distribute our data (either adjusting the threshold, or tuning the tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+----------------+---+-------+-------------+---------------+--------------+-----------+------------+-------------------+---------------+--------------------+\n",
      "|event|white_result|       first_two|ECO|EloDiff|      Opening|game_complexity| opening_class|opening_ohe|event_vector|white_result_vector|       ECO_Type|            features|\n",
      "+-----+------------+----------------+---+-------+-------------+---------------+--------------+-----------+------------+-------------------+---------------+--------------------+\n",
      "|Blitz|        loss|[Na3 d5, Nh3 e6]|A00|    152|Sodium Attack|              4|Flank openings|        0.0|         0.0|                0.0|(492,[0],[1.0])|(494,[0,492],[1.0...|\n",
      "|Blitz|        loss| [Na3 d5, c3 c5]|A00|    -56|Sodium Attack|              5|Flank openings|        0.0|         0.0|                0.0|(492,[0],[1.0])|(494,[0,492],[1.0...|\n",
      "+-----+------------+----------------+---+-------+-------------+---------------+--------------+-----------+------------+-------------------+---------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation to Fine Tune Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1444.2239694595337\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# cross validation:\n",
    "# Reference: https://stackoverflow.com/questions/32769573/how-to-cross-validate-randomforest-model\n",
    "# Random forest parameters: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.RandomForestClassifier.html?highlight=randomforest#pyspark.ml.classification.RandomForestClassifier\n",
    "# Tuning random forest parameter example: https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Number of trees in random forest \n",
    "num_trees = [20, 30]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 8]\n",
    "# Criterion used for information gain calculation\n",
    "criterion = [\"entropy\", \"gini\"]\n",
    "#criterion = [\"gini\"]\n",
    "# Maximum number of bins used for discretizing continuous features and for choosing how to split on features at each node.\n",
    "max_bins = [28, 32]\n",
    "# max_bins = [32]\n",
    "# raction of the training data used for learning each decision tree, in range (0, 1].'\n",
    "# samping_rate = [1]\n",
    "samping_rate = [0.8, 1]\n",
    "\n",
    "grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, num_trees) \\\n",
    "    .addGrid(rf.maxDepth, max_depth) \\\n",
    "    .addGrid(rf.impurity, criterion) \\\n",
    "    .addGrid(rf.maxBins, max_bins) \\\n",
    "    .addGrid(rf.subsamplingRate, samping_rate) \\\n",
    "    .build()\n",
    "\n",
    "numFolds = 2\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=grid,\n",
    "    evaluator=auc_evaluator,\n",
    "    numFolds=numFolds,\n",
    "    parallelism=4,\n",
    "    seed = SEED)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "import time\n",
    "t0 = time.time()\n",
    "cvmodel = crossval.fit(trainingData)\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain auc for each parameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6592152589816127,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6527140805638456,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6564596475083855,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6536965734882761,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6570392983633386,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6571020078060197,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6564689289569365,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6599613216986332,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6665472871077955,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6591653315074908,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6669045506118176,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6637696485355646,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6665138245379626,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.656296486298419,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6721589402550019,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6587668040054707,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6496554325628245,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6541107374948602,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6526205730978192,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.652734589167994,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6485661010348369,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6491321706638633,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6479681267688692,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6510370991369564,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6614035739682997,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6711592438887064,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6690466770560883,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6654848596886249,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6528033974723391,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6610586254824422,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 28,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}),\n",
       " (0.6526801390721475,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}),\n",
       " (0.6619232104998565,\n",
       "  {Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 30,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       "   Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html?highlight=crossvalidator\n",
    "list(zip(cvmodel.avgMetrics, cvmodel.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the best model parameters and corresponding performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='RandomForestClassifier_924ded86070b', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_924ded86070b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 8, Param(parent='RandomForestClassifier_924ded86070b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='RandomForestClassifier_924ded86070b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='RandomForestClassifier_924ded86070b', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 0.8}\n",
      "0.6721589402550019\n"
     ]
    }
   ],
   "source": [
    "print(cvmodel.getEstimatorParamMaps()[np.argmax(cvmodel.avgMetrics)])\n",
    "print(cvmodel.avgMetrics[np.argmax(cvmodel.avgMetrics)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the best model the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AreaUnderROC: 0.6501412854172447\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test documents. cvModel uses the best model found.\n",
    "prediction_cv = cvmodel.transform(testingData)\n",
    "model_auc = auc_evaluator.evaluate(prediction_cv)\n",
    "print(\"Model AreaUnderROC: {}\".format(model_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[382172. 199590.]\n",
      " [227251. 347109.]]\n"
     ]
    }
   ],
   "source": [
    "designer_matrix = prediction_cv.select(['prediction','white_result_vector'])\n",
    "metrics_rdd = MulticlassMetrics(designer_matrix.rdd.map(tuple))\n",
    "print(metrics_rdd.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate multiple metrics for the best model\n",
    "\n",
    "numTrees = 30; maxDepth = 8; impurity = \"entropy\"; maxBins = 28; subsamplingRate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(numTrees=30, maxDepth=8, impurity = \"entropy\", maxBins = 28, subsamplingRate = 1, featuresCol='features', labelCol='white_result_vector', seed=SEED, leafCol=\"leafId\")\n",
    "# Create our transforms from our full dataset (considers all cases)\n",
    "\n",
    "rbestmodel = rf_best.fit(trainingData)\n",
    "prediction_best = rbestmodel.transform(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to an RDD to collect performance measures and confusion matrix\n",
    "metrics_rdd = MulticlassMetrics(prediction_best.select(['prediction','white_result_vector']).rdd.map(tuple))\n",
    "\n",
    "label = 1.0\n",
    "best_metrics = pd.DataFrame([['AUROC',     model_auc],\n",
    "                            ['Accuracy',  metrics_rdd.accuracy],\n",
    "                            ['Precision', metrics_rdd.precision(label)],\n",
    "                            ['Recall',    metrics_rdd.recall(label)],\n",
    "                            ['F1 Score',  metrics_rdd.fMeasure(label)]],\n",
    "                            columns=['Metric', 'Measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUROC</td>\n",
       "      <td>0.650141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.630643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.626828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.633918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.630353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric   Measure\n",
       "0      AUROC  0.650141\n",
       "1   Accuracy  0.630643\n",
       "2  Precision  0.626828\n",
       "3     Recall  0.633918\n",
       "4   F1 Score  0.630353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# recompose hierarcical data to dataframe\n",
    "# Plot the performances of each metric\n",
    "ax2 = sns.barplot(data=best_metrics, x='Measure', y='Metric', orient=\"h\")\n",
    "ax2.set(xlim=(0.495, 0.68))\n",
    "best_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the best model based on cross validation to obtain feature importance\n",
    "numTrees = 30; maxDepth = 8; impurity = \"entropy\"; maxBins = 28; subsamplingRate = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.timlrx.com/blog/feature-selection-using-feature-importance-score-creating-a-pyspark-estimator\n",
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['importance'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('importance', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(numTrees=30, maxDepth=8, impurity = \"entropy\", maxBins = 28, subsamplingRate = 1, featuresCol='features', labelCol='white_result_vector', seed=SEED, leafCol=\"leafId\")\n",
    "model_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                                    gametype_vectorizer,\n",
    "                                    result_vectorizor,\n",
    "                                    move_encoder,\n",
    "                                   features_assembler, \n",
    "                                   rf_best])\n",
    "rtmodel = model_pipeline.fit(df)\n",
    "df2 = rtmodel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>EloDiff</td>\n",
       "      <td>0.360950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>ECO_Type_C40</td>\n",
       "      <td>0.137927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ECO_Type_A00</td>\n",
       "      <td>0.068624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>ECO_Type_C20</td>\n",
       "      <td>0.044390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>39</td>\n",
       "      <td>ECO_Type_C34</td>\n",
       "      <td>0.042927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>51</td>\n",
       "      <td>ECO_Type_C22</td>\n",
       "      <td>0.036970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>25</td>\n",
       "      <td>ECO_Type_D20</td>\n",
       "      <td>0.032981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>ECO_Type_B20</td>\n",
       "      <td>0.029678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>ECO_Type_C41</td>\n",
       "      <td>0.023475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18</td>\n",
       "      <td>ECO_Type_A45</td>\n",
       "      <td>0.020388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19</td>\n",
       "      <td>ECO_Type_C02</td>\n",
       "      <td>0.020181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>ECO_Type_B00</td>\n",
       "      <td>0.016250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>35</td>\n",
       "      <td>ECO_Type_D06</td>\n",
       "      <td>0.016154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>54</td>\n",
       "      <td>ECO_Type_C57</td>\n",
       "      <td>0.014872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34</td>\n",
       "      <td>ECO_Type_C30</td>\n",
       "      <td>0.012943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27</td>\n",
       "      <td>ECO_Type_C21</td>\n",
       "      <td>0.011816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>113</td>\n",
       "      <td>ECO_Type_D21</td>\n",
       "      <td>0.009990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>ECO_Type_C55</td>\n",
       "      <td>0.007792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>ECO_Type_B21</td>\n",
       "      <td>0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>ECO_Type_B40</td>\n",
       "      <td>0.007482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx          name  importance\n",
       "0    490       EloDiff    0.360950\n",
       "12    10  ECO_Type_C40    0.137927\n",
       "2      0  ECO_Type_A00    0.068624\n",
       "7      5  ECO_Type_C20    0.044390\n",
       "41    39  ECO_Type_C34    0.042927\n",
       "53    51  ECO_Type_C22    0.036970\n",
       "27    25  ECO_Type_D20    0.032981\n",
       "10     8  ECO_Type_B20    0.029678\n",
       "6      4  ECO_Type_C41    0.023475\n",
       "20    18  ECO_Type_A45    0.020388\n",
       "21    19  ECO_Type_C02    0.020181\n",
       "9      7  ECO_Type_B00    0.016250\n",
       "37    35  ECO_Type_D06    0.016154\n",
       "56    54  ECO_Type_C57    0.014872\n",
       "36    34  ECO_Type_C30    0.012943\n",
       "29    27  ECO_Type_C21    0.011816\n",
       "115  113  ECO_Type_D21    0.009990\n",
       "19    17  ECO_Type_C55    0.007792\n",
       "18    16  ECO_Type_B21    0.007546\n",
       "32    30  ECO_Type_B40    0.007482"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureimp = ExtractFeatureImp(rtmodel.stages[-1].featureImportances, df2, \"features\").head(20)\n",
    "featureimp = featureimp.drop('vals', axis=1)\n",
    "featureimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='name'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "featureimp.sort_values('importance',inplace=True)\n",
    "featureimp.plot.barh(x='name', y='importance', rot =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel: uid=RandomForestClassifier_1d7a3308fdcf, numTrees=30, numClasses=2, numFeatures=492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel: uid=RandomForestClassifier_1d7a3308fdcf, numTrees=30, numClasses=2, numFeatures=492\n",
      "  Tree 0 (weight 1.0):\n",
      "    If (feature 130 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 130 not in {1.0})\n",
      "     If (feature 51 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 51 not in {1.0})\n",
      "      If (feature 7 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 7 not in {1.0})\n",
      "       If (feature 15 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 15 not in {1.0})\n",
      "        If (feature 17 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 17 not in {1.0})\n",
      "         If (feature 62 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 62 not in {1.0})\n",
      "          If (feature 113 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 113 not in {1.0})\n",
      "           Predict: 0.0\n",
      "  Tree 1 (weight 1.0):\n",
      "    If (feature 490 <= -1.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 490 > -1.5)\n",
      "     If (feature 30 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 30 not in {1.0})\n",
      "      If (feature 490 <= 157.5)\n",
      "       If (feature 91 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 91 not in {1.0})\n",
      "        If (feature 27 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 27 not in {1.0})\n",
      "         If (feature 15 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 15 not in {1.0})\n",
      "          If (feature 18 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 18 not in {1.0})\n",
      "           If (feature 279 in {1.0})\n",
      "            Predict: 0.0\n",
      "           Else (feature 279 not in {1.0})\n",
      "            Predict: 1.0\n",
      "      Else (feature 490 > 157.5)\n",
      "       Predict: 1.0\n",
      "  Tree 2 (weight 1.0):\n",
      "    If (feature 65 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 65 not in {1.0})\n",
      "     If (feature 19 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 19 not in {1.0})\n",
      "      If (feature 39 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 39 not in {1.0})\n",
      "       If (feature 121 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 121 not in {1.0})\n",
      "        If (feature 4 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 4 not in {1.0})\n",
      "         If (feature 10 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 10 not in {1.0})\n",
      "          If (feature 0 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 0 not in {1.0})\n",
      "           If (feature 20 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 20 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 3 (weight 1.0):\n",
      "    If (feature 215 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 215 not in {1.0})\n",
      "     If (feature 27 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 27 not in {1.0})\n",
      "      If (feature 10 in {1.0})\n",
      "       If (feature 490 <= 91.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 490 > 91.5)\n",
      "        Predict: 1.0\n",
      "      Else (feature 10 not in {1.0})\n",
      "       If (feature 39 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 39 not in {1.0})\n",
      "        If (feature 54 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 54 not in {1.0})\n",
      "         If (feature 7 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 7 not in {1.0})\n",
      "          If (feature 14 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 14 not in {1.0})\n",
      "           If (feature 47 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 47 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 4 (weight 1.0):\n",
      "    If (feature 39 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 39 not in {1.0})\n",
      "     If (feature 26 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 26 not in {1.0})\n",
      "      If (feature 20 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 20 not in {1.0})\n",
      "       If (feature 10 in {1.0})\n",
      "        If (feature 490 <= 91.5)\n",
      "         Predict: 0.0\n",
      "        Else (feature 490 > 91.5)\n",
      "         Predict: 1.0\n",
      "       Else (feature 10 not in {1.0})\n",
      "        Predict: 0.0\n",
      "  Tree 5 (weight 1.0):\n",
      "    If (feature 18 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 18 not in {1.0})\n",
      "     If (feature 35 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 35 not in {1.0})\n",
      "      If (feature 490 <= -1.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 490 > -1.5)\n",
      "       If (feature 330 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 330 not in {1.0})\n",
      "        Predict: 1.0\n",
      "  Tree 6 (weight 1.0):\n",
      "    If (feature 25 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 25 not in {1.0})\n",
      "     If (feature 16 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 16 not in {1.0})\n",
      "      If (feature 27 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 27 not in {1.0})\n",
      "       If (feature 55 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 55 not in {1.0})\n",
      "        If (feature 20 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 20 not in {1.0})\n",
      "         If (feature 39 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 39 not in {1.0})\n",
      "          If (feature 490 <= 21.5)\n",
      "           Predict: 0.0\n",
      "          Else (feature 490 > 21.5)\n",
      "           Predict: 1.0\n",
      "  Tree 7 (weight 1.0):\n",
      "    If (feature 62 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 62 not in {1.0})\n",
      "     If (feature 86 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 86 not in {1.0})\n",
      "      If (feature 39 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 39 not in {1.0})\n",
      "       If (feature 54 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 54 not in {1.0})\n",
      "        If (feature 18 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 18 not in {1.0})\n",
      "         If (feature 44 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 44 not in {1.0})\n",
      "          If (feature 0 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 0 not in {1.0})\n",
      "           If (feature 4 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 4 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 8 (weight 1.0):\n",
      "    If (feature 9 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 9 not in {1.0})\n",
      "     If (feature 25 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 25 not in {1.0})\n",
      "      If (feature 51 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 51 not in {1.0})\n",
      "       If (feature 27 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 27 not in {1.0})\n",
      "        If (feature 17 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 17 not in {1.0})\n",
      "         If (feature 0 in {1.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 0 not in {1.0})\n",
      "          If (feature 121 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 121 not in {1.0})\n",
      "           If (feature 15 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 15 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 9 (weight 1.0):\n",
      "    If (feature 19 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 19 not in {1.0})\n",
      "     If (feature 39 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 39 not in {1.0})\n",
      "      If (feature 54 in {1.0})\n",
      "       If (feature 490 <= -11.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 490 > -11.5)\n",
      "        Predict: 1.0\n",
      "      Else (feature 54 not in {1.0})\n",
      "       If (feature 7 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 7 not in {1.0})\n",
      "        If (feature 30 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 30 not in {1.0})\n",
      "         If (feature 107 in {1.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 107 not in {1.0})\n",
      "          If (feature 95 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 95 not in {1.0})\n",
      "           Predict: 0.0\n",
      "  Tree 10 (weight 1.0):\n",
      "    If (feature 18 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 18 not in {1.0})\n",
      "     If (feature 26 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 26 not in {1.0})\n",
      "      If (feature 31 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 31 not in {1.0})\n",
      "       If (feature 261 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 261 not in {1.0})\n",
      "        If (feature 55 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 55 not in {1.0})\n",
      "         If (feature 10 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 10 not in {1.0})\n",
      "          If (feature 39 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 39 not in {1.0})\n",
      "           If (feature 79 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 79 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 11 (weight 1.0):\n",
      "    If (feature 95 in {1.0})\n",
      "     If (feature 490 <= -11.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 490 > -11.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 95 not in {1.0})\n",
      "     If (feature 35 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 35 not in {1.0})\n",
      "      If (feature 25 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 25 not in {1.0})\n",
      "       If (feature 10 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 10 not in {1.0})\n",
      "        If (feature 4 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 4 not in {1.0})\n",
      "         If (feature 121 in {1.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 121 not in {1.0})\n",
      "          If (feature 9 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 9 not in {1.0})\n",
      "           Predict: 0.0\n",
      "  Tree 12 (weight 1.0):\n",
      "    If (feature 5 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 5 not in {1.0})\n",
      "     If (feature 49 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 49 not in {1.0})\n",
      "      If (feature 37 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 37 not in {1.0})\n",
      "       If (feature 54 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 54 not in {1.0})\n",
      "        If (feature 20 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 20 not in {1.0})\n",
      "         If (feature 70 in {1.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 70 not in {1.0})\n",
      "          If (feature 4 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 4 not in {1.0})\n",
      "           If (feature 25 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 25 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 13 (weight 1.0):\n",
      "    If (feature 142 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 142 not in {1.0})\n",
      "     If (feature 49 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 49 not in {1.0})\n",
      "      If (feature 490 <= -11.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 490 > -11.5)\n",
      "       If (feature 64 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 64 not in {1.0})\n",
      "        If (feature 304 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 304 not in {1.0})\n",
      "         If (feature 490 <= 157.5)\n",
      "          If (feature 490 <= 60.5)\n",
      "           If (feature 275 in {1.0})\n",
      "            Predict: 0.0\n",
      "           Else (feature 275 not in {1.0})\n",
      "            Predict: 1.0\n",
      "          Else (feature 490 > 60.5)\n",
      "           Predict: 1.0\n",
      "         Else (feature 490 > 157.5)\n",
      "          If (feature 283 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 283 not in {1.0})\n",
      "           Predict: 1.0\n",
      "  Tree 14 (weight 1.0):\n",
      "    If (feature 55 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 55 not in {1.0})\n",
      "     If (feature 30 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 30 not in {1.0})\n",
      "      If (feature 16 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 16 not in {1.0})\n",
      "       If (feature 54 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 54 not in {1.0})\n",
      "        If (feature 139 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 139 not in {1.0})\n",
      "         If (feature 7 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 7 not in {1.0})\n",
      "          If (feature 62 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 62 not in {1.0})\n",
      "           If (feature 34 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 34 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 15 (weight 1.0):\n",
      "    If (feature 27 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 27 not in {1.0})\n",
      "     If (feature 39 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 39 not in {1.0})\n",
      "      If (feature 339 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 339 not in {1.0})\n",
      "       If (feature 7 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 7 not in {1.0})\n",
      "        If (feature 130 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 130 not in {1.0})\n",
      "         If (feature 8 in {1.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 8 not in {1.0})\n",
      "          If (feature 55 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 55 not in {1.0})\n",
      "           If (feature 25 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 25 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 16 (weight 1.0):\n",
      "    If (feature 27 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 27 not in {1.0})\n",
      "     If (feature 10 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 10 not in {1.0})\n",
      "      If (feature 5 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 5 not in {1.0})\n",
      "       If (feature 54 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 54 not in {1.0})\n",
      "        If (feature 22 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 22 not in {1.0})\n",
      "         If (feature 43 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 43 not in {1.0})\n",
      "          If (feature 6 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 6 not in {1.0})\n",
      "           Predict: 0.0\n",
      "  Tree 17 (weight 1.0):\n",
      "    If (feature 37 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 37 not in {1.0})\n",
      "     If (feature 10 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 10 not in {1.0})\n",
      "      If (feature 107 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 107 not in {1.0})\n",
      "       If (feature 18 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 18 not in {1.0})\n",
      "        If (feature 17 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 17 not in {1.0})\n",
      "         If (feature 23 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 23 not in {1.0})\n",
      "          If (feature 44 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 44 not in {1.0})\n",
      "           If (feature 113 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 113 not in {1.0})\n",
      "            Predict: 0.0\n",
      "  Tree 18 (weight 1.0):\n",
      "    If (feature 18 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 18 not in {1.0})\n",
      "     If (feature 54 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 54 not in {1.0})\n",
      "      If (feature 9 in {1.0})\n",
      "       If (feature 490 <= 60.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 490 > 60.5)\n",
      "        Predict: 1.0\n",
      "      Else (feature 9 not in {1.0})\n",
      "       If (feature 10 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 10 not in {1.0})\n",
      "        If (feature 490 <= -1.5)\n",
      "         Predict: 0.0\n",
      "        Else (feature 490 > -1.5)\n",
      "         Predict: 1.0\n",
      "  Tree 19 (weight 1.0):\n",
      "    If (feature 34 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 34 not in {1.0})\n",
      "     If (feature 113 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 113 not in {1.0})\n",
      "      If (feature 15 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 15 not in {1.0})\n",
      "       If (feature 189 in {1.0})\n",
      "        If (feature 490 <= 33.5)\n",
      "         Predict: 0.0\n",
      "        Else (feature 490 > 33.5)\n",
      "         Predict: 1.0\n",
      "       Else (feature 189 not in {1.0})\n",
      "        If (feature 4 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 4 not in {1.0})\n",
      "         If (feature 79 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 79 not in {1.0})\n",
      "          If (feature 490 <= -1.5)\n",
      "           If (feature 379 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 379 not in {1.0})\n",
      "            Predict: 0.0\n",
      "          Else (feature 490 > -1.5)\n",
      "           Predict: 1.0\n",
      "  Tree 20 (weight 1.0):\n",
      "    If (feature 49 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 49 not in {1.0})\n",
      "     If (feature 10 in {1.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 10 not in {1.0})\n",
      "      If (feature 16 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 16 not in {1.0})\n",
      "       If (feature 6 in {1.0})\n",
      "        If (feature 490 <= 33.5)\n",
      "         Predict: 0.0\n",
      "        Else (feature 490 > 33.5)\n",
      "         Predict: 1.0\n",
      "       Else (feature 6 not in {1.0})\n",
      "        If (feature 19 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 19 not in {1.0})\n",
      "         If (feature 62 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 62 not in {1.0})\n",
      "          If (feature 27 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 27 not in {1.0})\n",
      "           Predict: 0.0\n",
      "  Tree 21 (weight 1.0):\n",
      "    If (feature 35 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 35 not in {1.0})\n",
      "     If (feature 51 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 51 not in {1.0})\n",
      "      If (feature 113 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 113 not in {1.0})\n",
      "       If (feature 47 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 47 not in {1.0})\n",
      "        If (feature 30 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 30 not in {1.0})\n",
      "         If (feature 6 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 6 not in {1.0})\n",
      "          If (feature 2 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 2 not in {1.0})\n",
      "           Predict: 0.0\n",
      "  Tree 22 (weight 1.0):\n",
      "    If (feature 490 <= -1.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 490 > -1.5)\n",
      "     Predict: 1.0\n",
      "  Tree 23 (weight 1.0):\n",
      "    If (feature 5 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 5 not in {1.0})\n",
      "     If (feature 8 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 8 not in {1.0})\n",
      "      If (feature 95 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 95 not in {1.0})\n",
      "       If (feature 51 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 51 not in {1.0})\n",
      "        If (feature 35 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 35 not in {1.0})\n",
      "         If (feature 20 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 20 not in {1.0})\n",
      "          If (feature 16 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 16 not in {1.0})\n",
      "           If (feature 121 in {1.0})\n",
      "            Predict: 0.0\n",
      "           Else (feature 121 not in {1.0})\n",
      "            Predict: 1.0\n",
      "  Tree 24 (weight 1.0):\n",
      "    If (feature 91 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 91 not in {1.0})\n",
      "     If (feature 19 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 19 not in {1.0})\n",
      "      If (feature 5 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 5 not in {1.0})\n",
      "       If (feature 186 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 186 not in {1.0})\n",
      "        If (feature 18 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 18 not in {1.0})\n",
      "         If (feature 10 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 10 not in {1.0})\n",
      "          Predict: 0.0\n",
      "  Tree 25 (weight 1.0):\n",
      "    If (feature 16 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 16 not in {1.0})\n",
      "     If (feature 121 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 121 not in {1.0})\n",
      "      If (feature 113 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 113 not in {1.0})\n",
      "       If (feature 84 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 84 not in {1.0})\n",
      "        If (feature 6 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 6 not in {1.0})\n",
      "         If (feature 9 in {1.0})\n",
      "          If (feature 490 <= -11.5)\n",
      "           Predict: 0.0\n",
      "          Else (feature 490 > -11.5)\n",
      "           Predict: 1.0\n",
      "         Else (feature 9 not in {1.0})\n",
      "          If (feature 10 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 10 not in {1.0})\n",
      "           Predict: 0.0\n",
      "  Tree 26 (weight 1.0):\n",
      "    If (feature 61 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 61 not in {1.0})\n",
      "     If (feature 19 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 19 not in {1.0})\n",
      "      If (feature 309 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 309 not in {1.0})\n",
      "       If (feature 85 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 85 not in {1.0})\n",
      "        If (feature 22 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 22 not in {1.0})\n",
      "         If (feature 0 in {1.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 0 not in {1.0})\n",
      "          If (feature 142 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 142 not in {1.0})\n",
      "           Predict: 1.0\n",
      "  Tree 27 (weight 1.0):\n",
      "    If (feature 19 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 19 not in {1.0})\n",
      "     If (feature 51 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 51 not in {1.0})\n",
      "      If (feature 22 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 22 not in {1.0})\n",
      "       If (feature 26 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 26 not in {1.0})\n",
      "        If (feature 10 in {1.0})\n",
      "         Predict: 1.0\n",
      "        Else (feature 10 not in {1.0})\n",
      "         If (feature 98 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 98 not in {1.0})\n",
      "          If (feature 0 in {1.0})\n",
      "           Predict: 0.0\n",
      "          Else (feature 0 not in {1.0})\n",
      "           If (feature 121 in {1.0})\n",
      "            Predict: 0.0\n",
      "           Else (feature 121 not in {1.0})\n",
      "            Predict: 1.0\n",
      "  Tree 28 (weight 1.0):\n",
      "    If (feature 130 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 130 not in {1.0})\n",
      "     If (feature 19 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 19 not in {1.0})\n",
      "      If (feature 47 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 47 not in {1.0})\n",
      "       If (feature 8 in {1.0})\n",
      "        Predict: 0.0\n",
      "       Else (feature 8 not in {1.0})\n",
      "        If (feature 30 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 30 not in {1.0})\n",
      "         If (feature 490 <= -1.5)\n",
      "          Predict: 0.0\n",
      "         Else (feature 490 > -1.5)\n",
      "          Predict: 1.0\n",
      "  Tree 29 (weight 1.0):\n",
      "    If (feature 27 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 27 not in {1.0})\n",
      "     If (feature 31 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 31 not in {1.0})\n",
      "      If (feature 18 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 18 not in {1.0})\n",
      "       If (feature 182 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 182 not in {1.0})\n",
      "        If (feature 5 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 5 not in {1.0})\n",
      "         If (feature 34 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 34 not in {1.0})\n",
      "          If (feature 39 in {1.0})\n",
      "           Predict: 1.0\n",
      "          Else (feature 39 not in {1.0})\n",
      "           If (feature 10 in {1.0})\n",
      "            Predict: 1.0\n",
      "           Else (feature 10 not in {1.0})\n",
      "            Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = rtmodel.stages[-1]\n",
    "display(tree) #visualize the decision tree model\n",
    "print(tree.toDebugString) #print the nodes of the decision tree model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
