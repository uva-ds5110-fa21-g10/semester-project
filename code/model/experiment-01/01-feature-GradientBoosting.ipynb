{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking at the individual features and their effectiveness. We are using Gradient Boosted Trees as the model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fractions import Fraction as frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"fa21-ds5110-group10-rk\") \\\n",
    "    .config(\"spark.driver.memory\", \"36g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://udc-ba33-31c0:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>fa21-ds5110-group10-rk</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=fa21-ds5110-group10-rk>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.cancelAllJobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we add in our cached dataset from our prior feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../../data/processed/chess_games_moves_model-limited.parquet\")\n",
    "trainData = spark.read.parquet(\"../../../data/processed/training-limited.parquet\")\n",
    "testData = spark.read.parquet(\"../../../data/processed/testing-limited.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[event: string, white_result: string, first_two: array<string>, ECO: string, EloDiff: int, Opening: string, game_complexity: int, opening_class: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()\n",
    "trainData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+----------------+---+-------+--------------------+---------------+-----------------+\n",
      "|event|white_result|       first_two|ECO|EloDiff|             Opening|game_complexity|    opening_class|\n",
      "+-----+------------+----------------+---+-------+--------------------+---------------+-----------------+\n",
      "|Blitz|        loss|[e4 e5, d4 exd4]|C22|     75|Center Game: Paul...|              4|       Open Games|\n",
      "|Blitz|        loss|  [d4 d5, c4 c6]|D45|     41|Semi-Slav Defense...|              5|Semi-Closed Games|\n",
      "+-----+------------+----------------+---+-------+--------------------+---------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we review the resulting data points of interest.\n",
    "We notice that ECO and the first two sets of moves are distinct of one another, and may influence the overall model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Turns: 250695\n",
      "ECO Types: 491\n",
      "+------------------+------+\n",
      "|         first_two| count|\n",
      "+------------------+------+\n",
      "|  [e4 e5, Nf3 Nc6]|180608|\n",
      "|   [e4 e5, Nf3 d6]| 68187|\n",
      "|  [e4 c5, Nf3 Nc6]| 44943|\n",
      "|[e4 d5, exd5 Qxd5]| 44702|\n",
      "|    [e4 e6, d4 d5]| 41142|\n",
      "+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None 2045840\n"
     ]
    }
   ],
   "source": [
    "print(\"First Turns: {}\".format(df.select(\"first_two\").distinct().count()))\n",
    "print(\"ECO Types: {}\".format(df.select(\"ECO\").distinct().count()))\n",
    "print( df.groupBy('first_two').count().sort(F.col(\"count\").desc()).show(5), df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now begin to build a model, keying in on the opening move and the white_result columns.\n",
    "Note that both of these are categorical values, so we will need to encode them using the StringIndexer for pyspark to do model evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "opening_vectorizor = StringIndexer(inputCol=\"ECO\", outputCol=\"opening_ohe\")\n",
    "gametype_vectorizer = StringIndexer(inputCol=\"event\", outputCol=\"event_vector\")\n",
    "class_vectorizer = StringIndexer(inputCol=\"opening_class\", outputCol=\"opening_class_vector\")\n",
    "# target\n",
    "result_vectorizor = StringIndexer(inputCol=\"white_result\", outputCol=\"white_result_vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform One-Hot Encoding on our Opening type (or ECO) and do our comparision.  THis will create a new column that we will use for our random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_encoder = OneHotEncoder(inputCols=[\"opening_ohe\"],\n",
    "                        outputCols=[\"ECO_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_encoder = OneHotEncoder(inputCols=[\"opening_class_vector\"],\n",
    "                        outputCols=[\"Class_Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the OHE of our ECO, we can combine it with other features to build out our predictors for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_assembler = VectorAssembler(inputCols=['ECO_Type', \"event_vector\",\"EloDiff\"], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is model-ready, we will do a split, fit, transform, and evaluation to determine the performance of our model.\n",
    "Note that we have chosen the default tunings, but in the future we will likely apply a cross-validation technique in pyspark to select the correct hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(maxDepth=5, maxIter=5, labelCol='white_result_vector', seed=1337, leafCol=\"leafId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                            gametype_vectorizer,\n",
    "                            class_vectorizer,\n",
    "                            result_vectorizor,\n",
    "                            move_encoder,\n",
    "                            class_encoder,\n",
    "                            features_assembler])\n",
    "ml_pipeline = Pipeline(stages=[gbt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_model = data_pipeline.fit(df)\n",
    "data_model_train = data_model.transform(trainData)\n",
    "data_model_test = data_model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ml_model = ml_pipeline.fit(data_model_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gbt = GBTClassifier(maxDepth=5, maxIter=10, labelCol='white_result_vector', seed=0, leafCol=\"leafId\")\n",
    "    \n",
    "    \n",
    "paramGrid = ParamGridBuilder().build()\n",
    "\n",
    "features_assembler = VectorAssembler(inputCols=[\"EloDiff\"], outputCol='features')         \n",
    "data_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                            gametype_vectorizer,\n",
    "                            result_vectorizor,\n",
    "                            move_encoder,\n",
    "                            features_assembler])\n",
    "ml_pipeline = Pipeline(stages=[gbt])\n",
    "        \n",
    "data_model = data_pipeline.fit(df)\n",
    "\n",
    "data_transformed = data_model.transform(df)\n",
    "        \n",
    "trainval = CrossValidator(estimator=ml_pipeline,\n",
    "                                        estimatorParamMaps=paramGrid,\n",
    "                                        evaluator=BinaryClassificationEvaluator(labelCol='white_result_vector'),\n",
    "                                        seed=0,\n",
    "                                        numFolds=10)\n",
    "cvModel = trainval.setParallelism(4).fit(data_transformed) #\n",
    "print((var,cvModel.bestModel.stages[-1].summary.accuracy,cvModel.bestModel.stages[-1].summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_selected = ['ECO_Type', \"event_vector\",\"EloDiff\"]\n",
    "\n",
    "def compute_univariate_aucs(df, target, varName, folds, max_iterations, seed):\n",
    "    \n",
    "    #encoder = OneHotEncoder(inputCol=target, outputCol=\"target_one\")\n",
    "    \n",
    "    gbt = GBTClassifier(maxDepth=5, maxIter=max_iterations, labelCol=target, seed=seed, leafCol=\"leafId\")\n",
    "    \n",
    "    \n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .build()\n",
    "        #.addGrid(gbt.subsamplingRate, [0.8, 1]) \\\n",
    "        #.addGrid(gbt.minInstancesPerNode, [2, 10,25]) \\\n",
    "        #.addGrid(gbt.maxDepth, [5, 8]) \\\n",
    "        \n",
    "    results = []\n",
    "    \n",
    "    features_assembler = VectorAssembler(inputCols=[varName], outputCol='features')         \n",
    "    data_pipeline = Pipeline(stages=[opening_vectorizor,\n",
    "                            gametype_vectorizer,\n",
    "                            class_vectorizer,\n",
    "                            result_vectorizor,\n",
    "                            move_encoder,\n",
    "                            class_encoder,\n",
    "                            features_assembler])\n",
    "    ml_pipeline = Pipeline(stages=[gbt])\n",
    "\n",
    "    data_model = data_pipeline.fit(df)\n",
    "    data_transformed = data_model.transform(df)\n",
    "\n",
    "    trainval = CrossValidator(estimator=ml_pipeline,\n",
    "                                    estimatorParamMaps=paramGrid,\n",
    "                                    evaluator=BinaryClassificationEvaluator(labelCol=target),\n",
    "                                    seed=seed,\n",
    "                                    numFolds=folds)\n",
    "    print(varName)\n",
    "    cvModel = trainval.setParallelism(4).fit(data_transformed)\n",
    "    \n",
    "    return list(zip(cvModel.avgMetrics, cvModel.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all data:\n",
    "* 'ECO_Type' = 0.5346240980278584\n",
    "** 0.5161513310165593\n",
    "* \"event_vector\" = 0.5013733029902808\n",
    "** 0.5010066514700525\n",
    "* \"EloDiff\" = 0.6877069013414416\n",
    "** 0.5705630031932493\n",
    "* \"Class_Type\" = 0.514669790072792\n",
    "** 0.50852791306638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECO_Type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5161513310165593, {})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1 = compute_univariate_aucs(df, 'white_result_vector', 'ECO_Type', 5, 10, 0)\n",
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_vector\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5010066514700525, {})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = compute_univariate_aucs(df, 'white_result_vector', \"event_vector\", 5, 10, 0)\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EloDiff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5705630031932493, {})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3 = compute_univariate_aucs(df, 'white_result_vector', \"EloDiff\", 5, 10, 0)\n",
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class_Type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.50852791306638, {})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4 = compute_univariate_aucs(df, 'white_result_vector', \"Class_Type\", 5, 10, 0)\n",
    "results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
